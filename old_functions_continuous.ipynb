{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd97911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from scipy.stats import binomtest\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from binance_historical_data import BinanceDataDumper\n",
    "\n",
    "\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04ee8da",
   "metadata": {},
   "source": [
    "# Download data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c3bca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_data_from_binance(symbol, temporalidad, start_year, end_year):\n",
    "    dumper = BinanceDataDumper(\n",
    "        path_dir_where_to_dump=\"data\",\n",
    "        asset_class=\"spot\",\n",
    "        data_type=\"klines\",\n",
    "        data_frequency=temporalidad\n",
    "    )\n",
    "\n",
    "    current = datetime.date(start_year, 1, 1)\n",
    "    end = datetime.date(end_year, 12, 31)\n",
    "\n",
    "    while current <= end:\n",
    "        next_month = (current.replace(day=1) + datetime.timedelta(days=32)).replace(day=1)\n",
    "        print(f\"Bajando {current} a {next_month - datetime.timedelta(days=1)}\")\n",
    "        dumper.dump_data(\n",
    "            tickers=[symbol],\n",
    "            date_start=current,\n",
    "            date_end=next_month - datetime.timedelta(days=1)\n",
    "        )\n",
    "        current = next_month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888ecaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_binance_files(folder_path):\n",
    "    column_names = [\n",
    "        'open_time', 'open', 'high', 'low', 'close', 'volume',\n",
    "        'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "        'taker_buy_volume_base', 'taker_buy_volume_quote', 'ignore'\n",
    "    ]\n",
    "\n",
    "    float_cols = ['open', 'high', 'low', 'close', 'volume',\n",
    "                  'quote_asset_volume', 'taker_buy_volume_base', 'taker_buy_volume_quote']\n",
    "    \n",
    "    dfs = []\n",
    "    files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".csv\")]\n",
    "\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f, names=column_names)\n",
    "        for unit in ['ms', 'us']:\n",
    "            try:\n",
    "                df['date'] = pd.to_datetime(df['open_time'], unit=unit)\n",
    "                df['close_time'] = pd.to_datetime(df['close_time'], unit=unit)\n",
    "                delta = df['date'].diff().dt.total_seconds().dropna()\n",
    "                if delta.mode().iloc[0] == 900:\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"Error parseando archivo: {f}\")\n",
    "            continue\n",
    "\n",
    "        df[float_cols] = df[float_cols].astype(float)\n",
    "        df = df.drop(columns='ignore')\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs).sort_values('open_time').reset_index(drop=True)\n",
    "    \n",
    "    # Crear columna con hora\n",
    "    df['hora'] = df['date'].dt.time\n",
    "\n",
    "    # Calcular tendencia\n",
    "    df['ema20'] = df['close'].ewm(span=20, adjust=False).mean()\n",
    "    df['tendency'] = np.where(df['close'] > df['ema20'], 1, -1)\n",
    "    df['prev_tendency'] = df['tendency'].shift(1)\n",
    "\n",
    "    # Tipo de vela y tamaño\n",
    "    df['type'] = np.where(df['close'] > df['open'], 'up', 'dw')\n",
    "    df['size'] = abs(df['close'] - df['open'])\n",
    "\n",
    "    # Engulf detection\n",
    "    o1 = df['open'].shift(1)\n",
    "    c1 = df['close'].shift(1)\n",
    "    o2 = df['open'].shift(2)\n",
    "    c2 = df['close'].shift(2)\n",
    "\n",
    "    engulf_up = (\n",
    "        (c1 > o1) & (c2 < o2) &\n",
    "        (o1 < c2) & (c1 > o2)\n",
    "    )\n",
    "\n",
    "    engulf_dw = (\n",
    "        (c1 < o1) & (c2 > o2) &\n",
    "        (o1 > c2) & (c1 < o2)\n",
    "    )\n",
    "\n",
    "    df['engulf'] = 0\n",
    "    df.loc[engulf_up, 'engulf'] = 1\n",
    "    df.loc[engulf_dw, 'engulf'] = -1\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455c8c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_binance_files(folder_path, expected_timeframe_seconds=None):\n",
    "\n",
    "    column_names = [\n",
    "        'open_time', 'open', 'high', 'low', 'close', 'volume',\n",
    "        'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "        'taker_buy_volume_base', 'taker_buy_volume_quote', 'ignore'\n",
    "    ]\n",
    "\n",
    "    float_cols = ['open', 'high', 'low', 'close', 'volume',\n",
    "                  'quote_asset_volume', 'taker_buy_volume_base', 'taker_buy_volume_quote']\n",
    "    \n",
    "    dfs = []\n",
    "    files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".csv\")]\n",
    "\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f, names=column_names)\n",
    "        for unit in ['ms', 'us']:\n",
    "            try:\n",
    "                df['date'] = pd.to_datetime(df['open_time'], unit=unit)\n",
    "                df['close_time'] = pd.to_datetime(df['close_time'], unit=unit)\n",
    "                delta = df['date'].diff().dt.total_seconds().dropna()\n",
    "                mode_delta = delta.mode().iloc[0]\n",
    "\n",
    "                if expected_timeframe_seconds is None or mode_delta == expected_timeframe_seconds:\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"Archivo descartado por timeframe: {f}\")\n",
    "            continue\n",
    "\n",
    "        df[float_cols] = df[float_cols].astype(float)\n",
    "        df = df.drop(columns='ignore')\n",
    "        dfs.append(df)\n",
    "\n",
    "    if not dfs:\n",
    "        print(\"No se cargaron archivos.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.concat(dfs).sort_values('open_time').reset_index(drop=True)\n",
    "    \n",
    "    # Crear columna con hora\n",
    "    df['hora'] = df['date'].dt.time\n",
    "\n",
    "    # Calcular tendencia\n",
    "    df['ema20'] = df['close'].ewm(span=20, adjust=False).mean()\n",
    "    df['tendency'] = np.where(df['close'] > df['ema20'], 1, -1)\n",
    "    df['prev_tendency'] = df['tendency'].shift(1)\n",
    "\n",
    "    # Tipo de vela y tamaño\n",
    "    df['type'] = np.where(df['close'] > df['open'], 'up', 'dw')\n",
    "    df['size'] = abs(df['close'] - df['open'])\n",
    "\n",
    "    # Engulf detection\n",
    "    o1 = df['open'].shift(1)\n",
    "    c1 = df['close'].shift(1)\n",
    "    o2 = df['open'].shift(2)\n",
    "    c2 = df['close'].shift(2)\n",
    "\n",
    "    engulf_up = (\n",
    "        (c1 > o1) & (c2 < o2) &\n",
    "        (o1 < c2) & (c1 > o2)\n",
    "    )\n",
    "\n",
    "    engulf_dw = (\n",
    "        (c1 < o1) & (c2 > o2) &\n",
    "        (o1 > c2) & (c1 < o2)\n",
    "    )\n",
    "\n",
    "    df['engulf'] = 0\n",
    "    df.loc[engulf_up, 'engulf'] = 1\n",
    "    df.loc[engulf_dw, 'engulf'] = -1\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1549c6f9",
   "metadata": {},
   "source": [
    "# N-order matrix, with tendency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a6b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_n_matrix(df, order=1, time_filter=None, use_tendency=True, use_engulf=False, vis=True):\n",
    "    df = df.copy()\n",
    "\n",
    "    df['type'] = np.where(df['close'] > df['open'], 'up', 'dw')\n",
    "\n",
    "    for i in range(1, order + 1):\n",
    "        df[f'prev_{i}'] = df['type'].shift(i)\n",
    "\n",
    "    required_cols = [f'prev_{i}' for i in range(1, order + 1)]\n",
    "    if use_tendency:\n",
    "        required_cols.append('prev_tendency')\n",
    "    if use_engulf:\n",
    "        required_cols.append('engulf')\n",
    "\n",
    "    df_valid = df.dropna(subset=required_cols).copy()\n",
    "\n",
    "    if order == 1:\n",
    "        df_valid['pattern'] = df_valid['prev_1']\n",
    "    else:\n",
    "        pattern_cols = [f'prev_{i}' for i in range(order, 0, -1)]\n",
    "        df_valid['pattern'] = df_valid[pattern_cols].agg('_'.join, axis=1)\n",
    "\n",
    "    if use_tendency:\n",
    "        df_valid['tendency'] = df_valid['prev_tendency'].astype(int)\n",
    "\n",
    "    if use_engulf:\n",
    "        df_valid['engulf'] = df_valid['engulf'].astype(int)\n",
    "\n",
    "    if time_filter:\n",
    "        h_open, m_open = time_filter[\"open\"]\n",
    "        h_close, m_close = time_filter[\"close\"]\n",
    "        df_valid = df_valid[\n",
    "            (df_valid['hora'] >= datetime.time(h_open, m_open)) &\n",
    "            (df_valid['hora'] <= datetime.time(h_close, m_close))\n",
    "        ].copy()\n",
    "\n",
    "    group_cols = ['pattern']\n",
    "    if use_tendency:\n",
    "        group_cols.append('tendency')\n",
    "    if use_engulf:\n",
    "        group_cols.append('engulf')\n",
    "    group_cols.append('type')\n",
    "\n",
    "    transition_counts = df_valid.groupby(group_cols).size().unstack(fill_value=0)\n",
    "    transition_matrix = transition_counts.div(transition_counts.sum(axis=1), axis=0)\n",
    "\n",
    "    if 'compute_tests' in globals():\n",
    "        tests = transition_counts.apply(compute_tests, axis=1)\n",
    "        transition_matrix = transition_matrix.join(tests)\n",
    "\n",
    "    if vis:\n",
    "        print(\"Matriz de transición (probabilidades):\")\n",
    "        print(transition_matrix.round(4))\n",
    "        print(\"\\nMatriz de transición (ocurrencias):\")\n",
    "        print(transition_counts.round(4))\n",
    "\n",
    "    return transition_matrix, transition_counts, df_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c244383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calcular los tests y agregarlos como columnas\n",
    "def compute_tests(row):\n",
    "    up = row.get('up', 0)\n",
    "    dw = row.get('dw', 0)\n",
    "    total = up + dw\n",
    "\n",
    "    # Test binomial (¿es el número de 'up' significativamente distinto de 50%?)\n",
    "    binom_p = binomtest(up, n=total, p=0.5, alternative='two-sided').pvalue if total > 0 else np.nan\n",
    "\n",
    "    return pd.Series({ 'binom_p': binom_p})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0485f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_significant_probabilities(transition_matrix, transition_counts, p_binom=0.05):\n",
    "\n",
    "    # Filtrar por significancia estadística (binom_p < 0.05)\n",
    "    significant_idx = transition_matrix[transition_matrix['binom_p'] < p_binom].index\n",
    "\n",
    "    # Filtrar ambas matrices\n",
    "    significant_probs = transition_matrix.loc[significant_idx]\n",
    "    significant_counts = transition_counts.loc[significant_idx]\n",
    "\n",
    "    print(\"Matriz de probabilidades (significativas):\")\n",
    "    print(significant_probs.round(4))\n",
    "\n",
    "    print(\"\\nMatriz de ocurrencias (correspondiente):\")\n",
    "    print(significant_counts)\n",
    "\n",
    "    return significant_probs, significant_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e44d99f",
   "metadata": {},
   "source": [
    "# Estrategia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e155ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_max_drawdown(series):\n",
    "    s = pd.Series(series, dtype=float)\n",
    "    if s.empty:\n",
    "        return {\"mdd\": 0.0, \"mdd_pct\": 0.0}\n",
    "    peak = s.cummax()\n",
    "    dd = peak - s\n",
    "    mdd = float(dd.max())\n",
    "    argmax_dd = int(np.nanargmax(dd.values))\n",
    "    peak_at_mdd = float(peak.iloc[argmax_dd]) if mdd > 0 else float(peak.iloc[0])\n",
    "    mdd_pct = float(mdd / peak_at_mdd) if peak_at_mdd != 0 else 0.0\n",
    "    return {\"mdd\": mdd, \"mdd_pct\": mdd_pct}\n",
    "\n",
    "def simulate_continuous_strategy(\n",
    "    df,\n",
    "    transition_matrix,\n",
    "    pattern,\n",
    "    tendency,\n",
    "    max_adverse_move,\n",
    "    minimum_range_movement,\n",
    "    stake=1,\n",
    "    vis=False,\n",
    "    comission=0.002,\n",
    "):\n",
    "    min_range_before_pattern = minimum_range_movement\n",
    "    orden = len(transition_matrix.index[0][0].split(\"_\"))\n",
    "    row = transition_matrix.loc[(pattern, tendency)]\n",
    "    prob_up = row[\"up\"]\n",
    "    prob_dw = row[\"dw\"]\n",
    "    expected = \"up\" if prob_up > prob_dw else \"dw\"\n",
    "    prob_expected = prob_up if prob_up > prob_dw else prob_dw\n",
    "\n",
    "    capital = 0.0\n",
    "    capital_adjusted = 0.0\n",
    "    results = []\n",
    "\n",
    "    for i in range(orden, len(df) - 1):\n",
    "        actual_tendency = df.loc[i - 1, \"tendency\"]\n",
    "        entry_time = df.loc[i + 1, \"date\"]\n",
    "        pattern_i = \"_\".join(df.loc[i - orden : i - 1, \"type\"].values.tolist())\n",
    "\n",
    "        if pattern_i == pattern and actual_tendency == tendency:\n",
    "            if min_range_before_pattern is not None:\n",
    "                open_max = df.loc[i - orden : i - 1, \"open\"].max()\n",
    "                close_max = df.loc[i - orden : i - 1, \"close\"].max()\n",
    "                open_min = df.loc[i - orden : i - 1, \"open\"].min()\n",
    "                close_min = df.loc[i - orden : i - 1, \"close\"].min()\n",
    "                prior_range = max(open_max, close_max) - min(open_min, close_min)\n",
    "                if prior_range < min_range_before_pattern:\n",
    "                    continue\n",
    "\n",
    "            row_candle = df.iloc[i + 1]\n",
    "            entry_price = row_candle[\"open\"]\n",
    "            exit_price = row_candle[\"close\"]\n",
    "            low = row_candle[\"low\"]\n",
    "            high = row_candle[\"high\"]\n",
    "            direction = 1 if expected == \"up\" else -1\n",
    "\n",
    "            hit_stop = False\n",
    "            if max_adverse_move is not None:\n",
    "                if direction == 1 and low <= entry_price - max_adverse_move:\n",
    "                    hit_stop = True\n",
    "                elif direction == -1 and high >= entry_price + max_adverse_move:\n",
    "                    hit_stop = True\n",
    "\n",
    "            if hit_stop:\n",
    "                pnl = -stake * max_adverse_move\n",
    "            else:\n",
    "                price_diff = (exit_price - entry_price) * direction\n",
    "                pnl = stake * price_diff\n",
    "\n",
    "            pnl_adjusted = pnl * (0.5 + prob_expected)\n",
    "\n",
    "            capital = capital + pnl - comission\n",
    "            capital_adjusted = capital_adjusted + pnl_adjusted - comission\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"index\": i,\n",
    "                    \"entry_time\": entry_time,\n",
    "                    \"entry_price\": entry_price,\n",
    "                    \"exit_price\": exit_price,\n",
    "                    \"pnl\": pnl,\n",
    "                    \"capital\": capital,\n",
    "                    \"capital_adjusted\": capital_adjusted,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "\n",
    "    n_trades = len(df_results)\n",
    "    if not df_results.empty:\n",
    "        n_days = df_results[\"entry_time\"].dt.date.nunique()\n",
    "    else:\n",
    "        n_days = 0\n",
    "    if n_days > 0:\n",
    "        avg_trades_per_day = n_trades / n_days\n",
    "    else:\n",
    "        avg_trades_per_day = 0.0\n",
    "\n",
    "    if vis:\n",
    "        print(f\"Operaciones totales: {n_trades}\")\n",
    "        print(f\"Promedio por día: {avg_trades_per_day:.2f}\")\n",
    "        print(f\"Capital final: {capital:.2f}\")\n",
    "\n",
    "    if \"capital\" in df_results.columns:\n",
    "        mdd_capital = compute_max_drawdown(df_results[\"capital\"])\n",
    "    else:\n",
    "        mdd_capital = {\"mdd\": 0.0, \"mdd_pct\": 0.0}\n",
    "    if \"capital_adjusted\" in df_results.columns:\n",
    "        mdd_capital_adj = compute_max_drawdown(df_results[\"capital_adjusted\"])\n",
    "    else:\n",
    "        mdd_capital_adj = {\"mdd\": 0.0, \"mdd_pct\": 0.0}\n",
    "\n",
    "    metrics = {\n",
    "        \"mdd_capital\": mdd_capital,\n",
    "        \"mdd_capital_adjusted\": mdd_capital_adj,\n",
    "        \"n_trades\": int(n_trades),\n",
    "        \"avg_trades_per_day\": float(avg_trades_per_day),\n",
    "        \"final_capital\": float(capital),\n",
    "        \"final_capital_adjusted\": float(capital_adjusted),\n",
    "    }\n",
    "    df_results.attrs[\"metrics\"] = metrics\n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a436d3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_over_patterns(df, \n",
    "                    relevant_transition_matrix, \n",
    "                    max_adverse_move,\n",
    "                    minimum_range_movement,\n",
    "                    stake=1,\n",
    "                    vis=True                    \n",
    "                    ):\n",
    "\n",
    "    survival_strategies =[]\n",
    "    #print(\"Se mantienen solo las curvas cuya pendiente de ajuste lineal sea positiva, y que pasen más tiempo por encima del capital inicial\")\n",
    "    for index, row in relevant_transition_matrix.iterrows():\n",
    "        pattern, tendency = index  # índice es una tupla\n",
    "        print(f\"\\nEjecutando para patrón: {pattern}, tendencia: {tendency}\")\n",
    "        \n",
    "        resultados = simulate_continuous_strategy(df, \n",
    "                                                relevant_transition_matrix,\n",
    "                                                pattern,\n",
    "                                                tendency,\n",
    "                                                max_adverse_move,\n",
    "                                                minimum_range_movement,\n",
    "                                                stake,\n",
    "                                                vis)\n",
    "        \n",
    "        capital_final = resultados.iloc[-1]['capital']\n",
    "        \n",
    "        #print(f\"Ganancia: {capital_final:.2f}\")\n",
    "        \n",
    "        x = np.arange(len(resultados))\n",
    "        slope, _ = np.polyfit(x, resultados[\"capital\"], 1)\n",
    "        ratio_above = (resultados[\"capital\"] > 0).mean()\n",
    "\n",
    "        if slope > 0 and ratio_above > 0.5 and capital_final >0:\n",
    "            plot_equity_curve(resultados, pattern, tendency)\n",
    "            survival_strategies.append([pattern, \n",
    "                                        tendency,\n",
    "                                        max_adverse_move, \n",
    "                                        minimum_range_movement,\n",
    "                                        resultados])\n",
    "        else:\n",
    "            print(\"Pendiente negativa, o mucho tiempo debajo\")\n",
    "    \n",
    "    return survival_strategies\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8878b23",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7358e800",
   "metadata": {},
   "source": [
    "### Old versión, split de CV simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491e3d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_strategy(df, target_factor, order=3, stake=1, vis=True):\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "    total_len = len(df)\n",
    "    chunk_size = total_len // 4\n",
    "    splits = [\n",
    "        df.iloc[:chunk_size],\n",
    "        df.iloc[chunk_size:chunk_size*2],\n",
    "        df.iloc[chunk_size*2:chunk_size*3],\n",
    "        df.iloc[chunk_size*3:]\n",
    "    ]\n",
    "\n",
    "    total_capital = 0\n",
    "    performance_tracker = defaultdict(list)\n",
    "\n",
    "    for i in range(4):\n",
    "        fold_capital = 0\n",
    "        test_df = splits[i].reset_index(drop=True)\n",
    "        train_df = pd.concat([splits[j] for j in range(4) if j != i]).reset_index(drop=True)\n",
    "\n",
    "        transition_matrix, _, _ = order_n_matrix(train_df, order=order, vis=False)\n",
    "        relevant_transition_matrix = transition_matrix[(transition_matrix[\"dw\"] > \n",
    "                                                target_factor) | \n",
    "                                                (transition_matrix[\"up\"] >\n",
    "                                                target_factor)]\n",
    "\n",
    "        if vis:\n",
    "            print(f\"\\n=== Fold {i+1} ===\")\n",
    "            print(\"Combinaciones patrón-tendencia seleccionadas:\")\n",
    "            for idx in relevant_transition_matrix.index:\n",
    "                print(f\"  {idx}\")\n",
    "\n",
    "        for index in relevant_transition_matrix.index:\n",
    "            pattern, tendency = index\n",
    "            resultados = simulate_continuous_strategy(test_df,\n",
    "                                                    relevant_transition_matrix,\n",
    "                                                    pattern,\n",
    "                                                    tendency,\n",
    "                                                    stake,\n",
    "                                                    vis=False)\n",
    "            capital_final = resultados.iloc[-1]['capital']\n",
    "            ganancia = capital_final - 100\n",
    "\n",
    "            performance_tracker[index].append(ganancia)\n",
    "\n",
    "            if ganancia < 0 and vis:\n",
    "                print(f\"  Pérdida con patrón {pattern}, tendencia {tendency}: {ganancia:.2f}\")\n",
    "\n",
    "            fold_capital += ganancia\n",
    "            total_capital += ganancia\n",
    "\n",
    "        if vis:\n",
    "            print(f\"Capital generado en el fold {i+1}: {fold_capital:.2f}\")\n",
    "\n",
    "    patrones_sin_perdidas = [k for k, ganancias in performance_tracker.items() if all(g >= 0 for g in ganancias)]\n",
    "\n",
    "    print(\"\\n=== Ejecutando estrategia completa para patrones sin pérdidas ===\")\n",
    "    print(\"Combinaciones seleccionadas:\")\n",
    "    transition_matrix, _, _ = order_n_matrix(df, order=order, vis=False)\n",
    "\n",
    "    combinaciones_finales = []\n",
    "    total_final_capital = 0\n",
    "    daily_pnls = defaultdict(float)\n",
    "\n",
    "    for pattern, tendency in patrones_sin_perdidas:\n",
    "        row = transition_matrix.loc[(pattern, tendency)]\n",
    "        expected = 'up' if row['up'] > row['dw'] else 'dw'\n",
    "        print(f\"  ({pattern}, {tendency}, {expected})\")\n",
    "        combinaciones_finales.append((pattern, tendency, expected))\n",
    "\n",
    "        resultados = simulate_continuous_strategy(df,\n",
    "                                                transition_matrix,\n",
    "                                                pattern,\n",
    "                                                tendency,\n",
    "                                                stake,\n",
    "                                                vis=False)\n",
    "\n",
    "        resultados['day'] = resultados['entry_time'].dt.date\n",
    "        pnl_por_dia = resultados.groupby('day')['pnl'].sum()\n",
    "\n",
    "        for day, pnl in pnl_por_dia.items():\n",
    "            daily_pnls[day] += pnl\n",
    "\n",
    "        capital_final = resultados.iloc[-1]['capital']\n",
    "        ganancia = capital_final - 100\n",
    "        total_final_capital += ganancia\n",
    "\n",
    "    if combinaciones_finales:\n",
    "        print(f\"\\nCapital total acumulado usando solo patrones sin pérdidas: {total_final_capital:.2f}\")\n",
    "\n",
    "        df_patterns = pd.DataFrame(combinaciones_finales, columns=[\"pattern\", \"tendency\", \"expected\"])\n",
    "        df_patterns.to_csv(f'patterns_{symbol}.csv', index=False)\n",
    "\n",
    "        df_daily = pd.DataFrame(sorted(daily_pnls.items()), columns=['day', 'pnl'])\n",
    "        df_daily['capital'] = 100 + df_daily['pnl'].cumsum()\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df_daily['day'], df_daily['capital'], label='Equity Curve')\n",
    "        plt.title(f'Curva de equity diaria acumulada para {symbol}')\n",
    "        plt.xlabel('Fecha')\n",
    "        plt.ylabel('Capital')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No se encontraron patrones sin pérdidas para {symbol}.\")\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6076041",
   "metadata": {},
   "source": [
    "### Walk forward cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4f1551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_cross_validation(df, \n",
    "                                target_prob=0.53,\n",
    "                                order=3,\n",
    "                                stake=1,\n",
    "                                n_splits=5,\n",
    "                                min_train_profit=0.0,\n",
    "                                vis=False,\n",
    "                                per_split_plots=False, \n",
    "                                per_pattern_plots=False):\n",
    "    \n",
    "    d = df.sort_values('date').reset_index(drop=True).copy()\n",
    "    d['date'] = pd.to_datetime(d['date'], errors='coerce')\n",
    "    total = len(d)\n",
    "    if total < (n_splits + 1):\n",
    "        print(\"Data insuficiente para los splits solicitados.\"); return [], [], pd.DataFrame()\n",
    "\n",
    "    split_size = total // (n_splits + 1)\n",
    "    equity_times, equity_vals = [], []\n",
    "    capital = 100.0\n",
    "    patterns_log_rows = []\n",
    "\n",
    "    for s in range(n_splits):\n",
    "        train_end = split_size * (s + 1)\n",
    "        test_end  = split_size * (s + 2)\n",
    "        train_df  = d.iloc[:train_end].reset_index(drop=True)\n",
    "        test_df   = d.iloc[train_end:test_end].reset_index(drop=True)\n",
    "\n",
    "        transition_matrix, _, _ = order_n_matrix(train_df, order=order, vis=False)\n",
    "        relevant_tm = transition_matrix[(transition_matrix[\"dw\"] > target_prob) | (transition_matrix[\"up\"] > target_prob)]\n",
    "\n",
    "        tr0, tr1 = train_df['date'].iloc[0], train_df['date'].iloc[-1]\n",
    "        te0, te1 = (test_df['date'].iloc[0], test_df['date'].iloc[-1]) if not test_df.empty else (pd.NaT, pd.NaT)\n",
    "\n",
    "        print(f\"\\n=== Walk-Forward Split {s+1} ===\")\n",
    "        print(f\"Train: {tr0} → {tr1}\")\n",
    "        if not test_df.empty: print(f\"Test:  {te0} → {te1}\")\n",
    "        print(f\"Patrones seleccionados (por prob.): {len(relevant_tm)}\")\n",
    "\n",
    "        kept = []\n",
    "        for (pattern, tendency) in relevant_tm.index:\n",
    "            res_train = simulate_continuous_strategy(train_df, relevant_tm, pattern, tendency, stake, vis=False)\n",
    "            train_gain = 0.0 if res_train.empty else (res_train.iloc[-1]['capital'] - 100.0)\n",
    "            if train_gain > min_train_profit: kept.append((pattern, tendency))\n",
    "\n",
    "        print(f\"Patrones tras filtro de profit en TRAIN (> {min_train_profit:+.2f}): {len(kept)}\")\n",
    "        for (pattern, tendency) in kept:\n",
    "            row = relevant_tm.loc[(pattern, tendency)]\n",
    "            expected = 'up' if row['up'] > row['dw'] else 'dw'\n",
    "            patterns_log_rows.append({'split': s+1,'train_start': tr0,'train_end': tr1,'test_start': te0,'test_end': te1,'pattern': pattern,'tendency': tendency,'expected': expected,'prob_up': float(row['up']),'prob_dw': float(row['dw'])})\n",
    "            #print(f\"  KEEP: {pattern}, {tendency}, expected={expected} (up={row['up']:.3f}, dw={row['dw']:.3f})\")\n",
    "\n",
    "        trades_list = []\n",
    "        for (pattern, tendency) in kept:\n",
    "            res_test = simulate_continuous_strategy(test_df, relevant_tm, pattern, tendency, stake, vis=False)\n",
    "            if not res_test.empty:\n",
    "                trades_list.append(res_test[['entry_time','pnl']])\n",
    "                if per_pattern_plots:\n",
    "                    rp = res_test[['entry_time','pnl']].copy()\n",
    "                    rp['capital'] = 100 + rp['pnl'].cumsum()\n",
    "                    # Prepend baseline a 100 para que SIEMPRE arranque en 100\n",
    "                    baseline = rp.iloc[[0]].copy(); baseline['capital'] = 100; baseline['pnl'] = 0\n",
    "                    rp = pd.concat([baseline, rp], ignore_index=True)\n",
    "                    plt.figure(figsize=(9,4))\n",
    "                    plt.plot(rp['entry_time'], rp['capital'], linewidth=2)\n",
    "                    plt.title(f\"Patrón {pattern} | Tendencia {tendency} | Split {s+1}\")\n",
    "                    plt.xlabel(\"Tiempo\"); plt.ylabel(\"Capital\"); plt.grid(True); plt.tight_layout(); plt.show()\n",
    "\n",
    "        if trades_list:\n",
    "            trades_df = pd.concat(trades_list).sort_values('entry_time')\n",
    "            for _, r in trades_df.iterrows():\n",
    "                capital += r['pnl']; equity_times.append(r['entry_time']); equity_vals.append(capital)\n",
    "            if per_split_plots:\n",
    "                tmp = trades_df.copy()\n",
    "                tmp['capital'] = tmp['pnl'].cumsum()\n",
    "                baseline = tmp.iloc[[0]].copy(); baseline['capital'] = 100; baseline['pnl'] = 0\n",
    "                tmp = pd.concat([baseline, tmp], ignore_index=True)\n",
    "                plt.figure(figsize=(9,4))\n",
    "                plt.plot(tmp['entry_time'], tmp['capital'], linewidth=2)\n",
    "                plt.title(f\"Split {s+1} | Train: {tr0.date()}→{tr1.date()} | Test: {te0.date()}→{te1.date()}\")\n",
    "                plt.xlabel(\"Tiempo\"); plt.ylabel(\"Capital\"); plt.grid(True); plt.tight_layout(); plt.show()\n",
    "\n",
    "    if vis and equity_vals:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.plot(equity_times, equity_vals, linewidth=2, label=\"Equity (Walk-Forward)\")\n",
    "        plt.title(\"Curva de equity global (walk-forward, inicio fijo, profit-filter)\")\n",
    "        plt.xlabel(\"Tiempo\")\n",
    "        plt.ylabel(\"Capital\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    patterns_log = pd.DataFrame(patterns_log_rows)\n",
    "    return equity_times, equity_vals, patterns_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dda1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_equity_individual(output, pattern, tendency, min_ratio_above=0.5,\n",
    "                            initial_capital=100, min_trades=20,\n",
    "                            min_global_slope=0.0,\n",
    "                            plot=False):\n",
    "    if output.empty or len(output) < min_trades:\n",
    "        return False, None\n",
    "\n",
    "    output = output.sort_values(\"entry_time\").copy()\n",
    "    output[\"capital\"] = initial_capital + output[\"pnl\"].cumsum()\n",
    "\n",
    "    # % de velas en ganancia\n",
    "    ratio_above = (output[\"capital\"] > initial_capital).mean()\n",
    "    if ratio_above < min_ratio_above:\n",
    "        return False, None\n",
    "\n",
    "    # pendiente global\n",
    "    x = np.arange(len(output))\n",
    "    slope, _ = np.polyfit(x, output[\"capital\"], 1)\n",
    "    if slope < min_global_slope:\n",
    "        return False, None\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(output[\"entry_time\"], output[\"capital\"], label=\"Equity\")\n",
    "        plt.axhline(initial_capital, color=\"gray\", linestyle=\"--\")\n",
    "        plt.title(f\"Para {pattern} y tendencia {tendency}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    return True, {\n",
    "        \"final_capital\": output[\"capital\"].iloc[-1],\n",
    "        \"ratio_above\": ratio_above,\n",
    "        \"global_slope\": slope,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a82d09c",
   "metadata": {},
   "source": [
    "### Rolling window cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55c1213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_walk_forward(df, target_factor, order=3, stake=1, train_bars=50000, test_bars=5000, vis=True, per_window_plots=False):\n",
    "    d = df.sort_values('date').reset_index(drop=True).copy()\n",
    "    d['date'] = pd.to_datetime(d['date'], errors='coerce')\n",
    "\n",
    "    n = len(d)\n",
    "    start = train_bars\n",
    "    equity_times, equity_vals = [], []\n",
    "    capital = 100\n",
    "\n",
    "    while start < n - test_bars:\n",
    "        train_df = d.iloc[start-train_bars:start].reset_index(drop=True)\n",
    "        test_df  = d.iloc[start:start+test_bars].reset_index(drop=True)\n",
    "\n",
    "        # Matriz SOLO con train\n",
    "        transition_matrix, _, _ = order_n_matrix(train_df, order=order, vis=False)\n",
    "        relevant_tm = transition_matrix[(transition_matrix[\"dw\"] > target_factor) | (transition_matrix[\"up\"] > target_factor)]\n",
    "\n",
    "        # Mostrar info de la ventana y patrones seleccionados\n",
    "        print(f\"\\n=== Window ===\")\n",
    "        print(f\"Train: {train_df['date'].iloc[0]} → {train_df['date'].iloc[-1]}\")\n",
    "        print(f\"Test:  {test_df['date'].iloc[0]} → {test_df['date'].iloc[-1]}\")\n",
    "        #print(f\"Patrones seleccionados: {len(relevant_tm)}\")\n",
    "        for (pattern, tendency) in relevant_tm.index:\n",
    "            row = relevant_tm.loc[(pattern, tendency)]\n",
    "            expected = 'up' if row['up'] > row['dw'] else 'dw'\n",
    "            print(f\"  {pattern}, {tendency}, expected={expected}\")\n",
    "\n",
    "        trades = []\n",
    "        for (pattern, tendency) in relevant_tm.index:\n",
    "            res = simulate_continuous_strategy(test_df, relevant_tm, pattern, tendency, stake, vis=False)\n",
    "            if not res.empty:\n",
    "                trades.append(res[['entry_time','pnl']])\n",
    "\n",
    "        if trades:\n",
    "            trades = pd.concat(trades).sort_values('entry_time')\n",
    "            for _, r in trades.iterrows():\n",
    "                capital += r['pnl']\n",
    "                equity_times.append(r['entry_time'])\n",
    "                equity_vals.append(capital)\n",
    "\n",
    "            if per_window_plots:\n",
    "                tmp = trades.copy()\n",
    "                tmp['capital'] = 100 + tmp['pnl'].cumsum()\n",
    "                plt.figure(figsize=(9,4))\n",
    "                plt.plot(tmp['entry_time'], tmp['capital'])\n",
    "                plt.title(f\"Train: {train_df['date'].iloc[0].date()}→{train_df['date'].iloc[-1].date()} | Test: {test_df['date'].iloc[0].date()}→{test_df['date'].iloc[-1].date()}\")\n",
    "                plt.xlabel(\"Tiempo\"); plt.ylabel(\"Capital\"); plt.grid(True); plt.tight_layout(); plt.show()\n",
    "\n",
    "        start += test_bars\n",
    "\n",
    "    if vis and equity_vals:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.plot(equity_times, equity_vals, label=\"Equity (Rolling WF)\", linewidth=2)\n",
    "        plt.title(\"Curva de equity global (rolling walk-forward)\")\n",
    "        plt.xlabel(\"Tiempo\"); plt.ylabel(\"Capital\"); plt.grid(True); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "    return equity_times, equity_vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c4d2d6",
   "metadata": {},
   "source": [
    "# Visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9790518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_equity_curve(df_results,\n",
    "                    pattern=None,\n",
    "                    tendency=None,\n",
    "                    capital_cols=['capital']):\n",
    "    \n",
    "    if df_results.empty:\n",
    "        print(\"No hay operaciones para graficar.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    for col in capital_cols:\n",
    "        plt.plot(df_results[col], linewidth=2, label=col)\n",
    "\n",
    "    title = \"Evolución del capital\"\n",
    "    if pattern and tendency is not None:\n",
    "        title += f\" - Patrón: {pattern}, Tendencia: {tendency}\"\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Trade #\")\n",
    "    plt.ylabel(\"Capital\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3736fc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_equity_curves(df_results,\n",
    "                                label,\n",
    "                                pattern,\n",
    "                                tendency):\n",
    "    \n",
    "    if df_results.empty:\n",
    "        print(\"No hay operaciones para graficar.\")\n",
    "        return\n",
    "\n",
    "    plt.plot(pd.DataFrame(df_results), linewidth=2, label=label)\n",
    "\n",
    "    title = \"Evolución del capital\"\n",
    "    if pattern and tendency is not None:\n",
    "        title += f\" - Patrón: {pattern}, Tendencia: {tendency}\"\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Trade #\")\n",
    "    plt.ylabel(\"Capital\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2523b0c7",
   "metadata": {},
   "source": [
    "# Auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18abd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulate_continuous_strategy_dual(df, \n",
    "                                    transition_matrix,\n",
    "                                    pattern,\n",
    "                                    tendency,\n",
    "                                    stake=1,\n",
    "                                    time_filter=None,\n",
    "                                    vis=True):\n",
    "    d = df.copy()\n",
    "    if 'date' in d.columns:\n",
    "        d['date'] = pd.to_datetime(d['date'], errors='coerce')\n",
    "    elif 'datetime' in d.columns:\n",
    "        d['date'] = pd.to_datetime(d['datetime'], errors='coerce')\n",
    "    else:\n",
    "        d['date'] = pd.NaT\n",
    "\n",
    "    row = transition_matrix.loc[(pattern, tendency)]\n",
    "    prob_up = row['up']\n",
    "    prob_dw = row['dw']\n",
    "    expected = 'up' if prob_up > prob_dw else 'dw'\n",
    "    direction = 1 if expected == 'up' else -1\n",
    "\n",
    "    capital_close = 100\n",
    "    capital_open = 100\n",
    "    eq_close, eq_open = [], []\n",
    "    times = []\n",
    "\n",
    "    for i in range(3, len(d)-1):\n",
    "        prev3 = d.loc[i-3, 'type']\n",
    "        prev2 = d.loc[i-2, 'type']\n",
    "        prev1 = d.loc[i-1, 'type']\n",
    "        actual_tendency = d.loc[i-1, 'tendency']\n",
    "\n",
    "        if f\"{prev3}_{prev2}_{prev1}\" == pattern and actual_tendency == tendency:\n",
    "            t = d.loc[i+1, 'date']\n",
    "\n",
    "            # Caso 1: entrada en close[i]\n",
    "            entry_price_close = d.loc[i, 'close']\n",
    "            exit_price_close = d.loc[i+1, 'close']\n",
    "            pnl_close = stake * (exit_price_close - entry_price_close) * direction\n",
    "            capital_close += pnl_close\n",
    "            eq_close.append(capital_close)\n",
    "\n",
    "            # Caso 2: entrada en open[i+1]\n",
    "            entry_price_open = d.loc[i+1, 'open']\n",
    "            exit_price_open = d.loc[i+1, 'close']\n",
    "            pnl_open = stake * (exit_price_open - entry_price_open) * direction\n",
    "            capital_open += pnl_open\n",
    "            eq_open.append(capital_open)\n",
    "\n",
    "            times.append(t)\n",
    "\n",
    "    if vis:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(times, eq_close, label=\"Entrada close[i]\", linewidth=2)\n",
    "        plt.plot(times, eq_open, label=\"Entrada open[i+1]\", linewidth=2)\n",
    "        plt.title(f\"Evolución del capital - Patrón: {pattern}, Tendencia: {tendency}\")\n",
    "        plt.xlabel(\"Tiempo\")\n",
    "        plt.ylabel(\"Capital\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return eq_close, eq_open\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
