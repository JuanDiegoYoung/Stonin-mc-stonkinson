{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd97911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit, ParameterGrid\n",
    "import os\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from binance_historical_data import BinanceDataDumper\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from scipy.stats import entropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04ee8da",
   "metadata": {},
   "source": [
    "# Download data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c3bca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_data_from_binance(symbol, temporalidad, start_year, end_year):\n",
    "    dumper = BinanceDataDumper(\n",
    "        path_dir_where_to_dump=\"data\",\n",
    "        asset_class=\"spot\",\n",
    "        data_type=\"klines\",\n",
    "        data_frequency=temporalidad\n",
    "    )\n",
    "\n",
    "    current = datetime.date(start_year, 1, 1)\n",
    "    end = datetime.date(end_year, 12, 31)\n",
    "\n",
    "    while current <= end:\n",
    "        next_month = (current.replace(day=1) + datetime.timedelta(days=32)).replace(day=1)\n",
    "        print(f\"Bajando {current} a {next_month - datetime.timedelta(days=1)}\")\n",
    "        dumper.dump_data(\n",
    "            tickers=[symbol],\n",
    "            date_start=current,\n",
    "            date_end=next_month - datetime.timedelta(days=1)\n",
    "        )\n",
    "        current = next_month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888ecaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_binance_files(folder_path, lookback, future_candles_to_predict, use_time_filter=False, expected_timeframe_seconds=None):\n",
    "    column_names = [\n",
    "        'open_time', 'open', 'high', 'low', 'close', 'volume',\n",
    "        'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "        'taker_buy_volume_base', 'taker_buy_volume_quote', 'ignore'\n",
    "    ]\n",
    "\n",
    "    float_cols = ['open', 'high', 'low', 'close', 'volume',\n",
    "                'quote_asset_volume', 'taker_buy_volume_base', 'taker_buy_volume_quote']\n",
    "\n",
    "    dfs = []\n",
    "    files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".csv\")]\n",
    "\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f, names=column_names)\n",
    "        for unit in ['ms', 'us']:\n",
    "            try:\n",
    "                df['date'] = pd.to_datetime(df['open_time'], unit=unit)\n",
    "                df['close_time'] = pd.to_datetime(df['close_time'], unit=unit)\n",
    "                delta = df['date'].diff().dt.total_seconds().dropna()\n",
    "                mode_delta = delta.mode().iloc[0]\n",
    "                if expected_timeframe_seconds is None or mode_delta == expected_timeframe_seconds:\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"Archivo descartado por timeframe: {f}\")\n",
    "            continue\n",
    "\n",
    "        df[float_cols] = df[float_cols].astype(float)\n",
    "        df = df.drop(columns='ignore')\n",
    "        dfs.append(df)\n",
    "\n",
    "    if not dfs:\n",
    "        print(\"No se cargaron archivos.\")\n",
    "        return pd.DataFrame(), []\n",
    "\n",
    "    df = pd.concat(dfs).sort_values('open_time').reset_index(drop=True)\n",
    "    df['hora'] = df['date'].dt.time\n",
    "\n",
    "    df = df.set_index('date')\n",
    "    if use_time_filter:\n",
    "        df = df.between_time(\"14:30\", \"21:00\")\n",
    "        if df.empty:\n",
    "            raise ValueError(\"No hay datos luego del filtro horario\")\n",
    "    df = df.reset_index()\n",
    "\n",
    "    df['ema20'] = df['close'].ewm(span=20, adjust=False).mean()\n",
    "    df['tendency'] = np.where(df['close'] > df['ema20'], 1, -1)\n",
    "    df['prev_tendency'] = df['tendency'].shift(1)\n",
    "    df['type'] = np.where(df['close'] > df['open'], 'up', 'dw')\n",
    "    df['type_encoded'] = df['type'].map({'dw': 0, 'up': 1})\n",
    "    df['size'] = abs(df['close'] - df['open'])\n",
    "    df['whole_size'] = df['high'] - df['low']\n",
    "    df['size_class'] = pd.qcut(df['size'], q=3, labels=['small', 'medium', 'large'], duplicates='drop')\n",
    "    df['size_encoded'] = df['size_class'].map({'small': 0, 'medium': 1, 'large': 2})\n",
    "    df['ema_htf'] = df['close'].ewm(span=200, adjust=False).mean()\n",
    "    df['tendency_htf'] = np.where(df['close'] > df['ema_htf'], 1, -1)\n",
    "\n",
    "    roll = df['volume'].rolling(20)\n",
    "    df['volume_norm'] = (df['volume'] - roll.mean()) / roll.std().replace(0, np.nan)\n",
    "\n",
    "    df['future_open'] = df['open'].shift(-future_candles_to_predict)\n",
    "    df['future_close'] = df['close'].shift(-future_candles_to_predict)\n",
    "    df['future_volume'] = df['volume'].shift(-future_candles_to_predict + 1).rolling(window=future_candles_to_predict).sum()\n",
    "    df['target'] = np.where(df['future_close'] > df['future_open'], 1, 0)\n",
    "\n",
    "    o1 = df['open'].shift(1)\n",
    "    c1 = df['close'].shift(1)\n",
    "    o2 = df['open'].shift(2)\n",
    "    c2 = df['close'].shift(2)\n",
    "    engulf_up = (c1 > o1) & (c2 < o2) & (o1 < c2) & (c1 > o2)\n",
    "    engulf_dw = (c1 < o1) & (c2 > o2) & (o1 > c2) & (c1 < o2)\n",
    "    df['engulf'] = 0\n",
    "    df.loc[engulf_up, 'engulf'] = 1\n",
    "    df.loc[engulf_dw, 'engulf'] = -1\n",
    "\n",
    "    shifts = [df['type_encoded'].shift(i).rename(f'prev_{i}') for i in range(1, lookback + 1)]\n",
    "    df_shifted = pd.concat([df] + shifts, axis=1)\n",
    "    df_shifted['prev_volume'] = df_shifted['volume_norm'].shift(1)\n",
    "\n",
    "    cols_prev = [f'prev_{i}' for i in range(1, lookback + 1)] + ['prev_volume']\n",
    "    cols_current = ['volume', 'tendency', 'tendency_htf', 'size', 'whole_size', 'type_encoded', 'volume_norm', 'quote_asset_volume', 'number_of_trades', 'taker_buy_volume_base', 'taker_buy_volume_quote']\n",
    "    cols = cols_prev + cols_current + ['target']\n",
    "\n",
    "    return df_shifted.dropna(subset=cols), cols[:-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93716be3",
   "metadata": {},
   "source": [
    "# Ejecución con incertidumbre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a743cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_impacto_de_thresholds(df_prep, \n",
    "                                features,\n",
    "                                param_rf_default=None,\n",
    "                                threshold_range=np.arange(0.50, 0.705, 0.02),\n",
    "                                n_splits=5,\n",
    "                                optimize_by=\"profit\"):\n",
    "\n",
    "    profit_factors = []\n",
    "    profits = []\n",
    "    n_trades = []\n",
    "    thresholds = []\n",
    "    equities = []\n",
    "\n",
    "    for thresh in threshold_range:\n",
    "        global future, use_uncertainty\n",
    "        use_uncertainty = True\n",
    "\n",
    "        equity, best_params, best_score, metrics, _ = grid_search_sobre_modelo_parallel(\n",
    "            grid_params=param_rf_default,\n",
    "            df=df_prep,\n",
    "            features=features,\n",
    "            vis_plot=False,\n",
    "            optimize_by=optimize_by\n",
    "        )\n",
    "\n",
    "        thresholds.append(thresh)\n",
    "        profit_factors.append(metrics.get(\"pf\", 0))\n",
    "        profits.append(equity[-1] - equity[0])\n",
    "        n_trades.append(len(equity) - 1)\n",
    "        equities.append(equity)\n",
    "\n",
    "    plot_uncertainty_metrics(thresholds, profit_factors, profits, n_trades)\n",
    "    plot_subplots_equity(equities, thresholds, profit_factors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b190de6",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e00b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grid_search_sobre_modelo_parallel(df,\n",
    "                                    features,\n",
    "                                    grid_params,\n",
    "                                    vis_plot):\n",
    "\n",
    "    def run_single_param(param_set):\n",
    "        equity, pf, metrics, feat_imp = evaluar_modelo_cv(df,\n",
    "                                                        features,\n",
    "                                                        param_set)\n",
    "        profit = equity[-1]\n",
    "        drawdown = max_drawdown(equity)\n",
    "        score_profit = profit\n",
    "        score_pf = pf\n",
    "        score_dd = profit / drawdown if drawdown > 0 else -np.inf\n",
    "        scores = (score_profit, score_pf, score_dd)\n",
    "        slopest = extract_slope(equity)\n",
    "        return scores, param_set, equity, metrics, feat_imp, slopest # -> results\n",
    "\n",
    "    results = Parallel(n_jobs=-1)(delayed(run_single_param)(param_set) for param_set in ParameterGrid(grid_params))\n",
    "\n",
    "    best_result_profit = max(results, key=lambda x: x[0][0])\n",
    "    best_result_pf = max(results, key=lambda x: x[0][1])\n",
    "    best_result_dd = max(results, key=lambda x: x[0][2])\n",
    "    \n",
    "    best_score_profit, best_params_profit, best_equity_profit, best_metrics_profit, best_feat_imp_profit, best_slope_profit = best_result_profit\n",
    "    best_score_pf, best_params_pf, best_equity_pf, best_metrics_pf, best_feat_imp_pf, best_slope_pf = best_result_pf\n",
    "    best_score_dd, best_params_dd, best_equity_dd, best_metrics_dd, best_feat_imp_dd, best_slope_dd = best_result_dd\n",
    "\n",
    "    best_equities = (best_equity_profit, best_equity_pf, best_equity_dd)\n",
    "    best_params = (best_params_profit, best_params_pf, best_params_dd)\n",
    "    best_score = (best_score_profit, best_score_pf, best_score_dd)\n",
    "    best_metrics = (best_metrics_profit, best_metrics_pf, best_metrics_dd)\n",
    "    best_feat_imp = (best_feat_imp_profit, best_feat_imp_pf, best_feat_imp_dd)\n",
    "    \n",
    "    if vis_plot:\n",
    "        equity_plot(best_equity_profit, \n",
    "                    best_equity_pf,\n",
    "                    best_equity_dd)\n",
    "        \n",
    "        importances = (best_feat_imp_profit, best_feat_imp_pf, best_feat_imp_dd)\n",
    "        plot_feature_importances(features, importances)\n",
    "\n",
    "    return best_equities, best_params, best_score, best_metrics, best_feat_imp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114a9ebe",
   "metadata": {},
   "source": [
    "# Evaluación del modelo con cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e75b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluar_modelo_cv(df_model_base,\n",
    "                    features,\n",
    "                    param_rf,\n",
    "                    threshold=0.5):\n",
    "\n",
    "    X = df_model_base[features]\n",
    "    y = df_model_base['target']\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    equity = [0]\n",
    "    \n",
    "    accuracies, precisions, recalls, f1s = [], [], [], []\n",
    "    feature_importances = None\n",
    "\n",
    "    all_certainties = []\n",
    "    all_entropies = []\n",
    "\n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        clf = RandomForestClassifier(**param_rf, random_state=0)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        if train_idx[-1] == train_idx[-1]:\n",
    "            feature_importances = clf.feature_importances_\n",
    "\n",
    "        probs = clf.predict_proba(X_test)\n",
    "        preds = np.argmax(probs, axis=1)\n",
    "        certainties = np.max(probs, axis=1)\n",
    "        entropies = entropy(probs.T)\n",
    "\n",
    "        all_certainties.extend(certainties)\n",
    "        all_entropies.extend(entropies)\n",
    "\n",
    "        df_model = df_model_base.iloc[test_idx].copy()\n",
    "        df_model['pred'] = preds\n",
    "        df_model['certainty'] = certainties\n",
    "        df_model['entropy'] = entropies\n",
    "        df_model['decision'] = 'no_trade'\n",
    "\n",
    "        if use_uncertainty:\n",
    "            mask = df_model['certainty'] > threshold\n",
    "\n",
    "            df_model.loc[mask & (df_model['pred'] == 1), 'decision'] = 'buy'\n",
    "            df_model.loc[mask & (df_model['pred'] == 0), 'decision'] = 'sell'\n",
    "            df_model = df_model[mask]\n",
    "        else:\n",
    "            df_model['decision'] = np.where(df_model['pred'] == 1, 'buy', 'sell')\n",
    "        \n",
    "        df_model['ret'] = np.where(\n",
    "            df_model['pred'] == 1,\n",
    "            (df_model['future_close'] - df_model['future_open']) / df_model['future_open'],\n",
    "            (df_model['future_open'] - df_model['future_close']) / df_model['future_open']\n",
    "        )\n",
    "        df_model = df_model.dropna(subset=['ret'])\n",
    "        \n",
    "        for r in df_model['ret']:\n",
    "            equity.append(equity[-1] + r)\n",
    "        \n",
    "        accuracies.append(accuracy_score(y_test, preds))\n",
    "        precisions.append(precision_score(y_test, preds, zero_division=0))\n",
    "        recalls.append(recall_score(y_test, preds, zero_division=0))\n",
    "        f1s.append(f1_score(y_test, preds, zero_division=0))\n",
    "\n",
    "    all_rets = np.diff(equity)\n",
    "    gains = sum(r for r in all_rets if r > 0)\n",
    "    losses = abs(sum(r for r in all_rets if r < 0))\n",
    "    profit_factor = gains / losses if losses > 0 else 0\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': np.mean(accuracies),\n",
    "        'precision': np.mean(precisions),\n",
    "        'recall': np.mean(recalls),\n",
    "        'f1_score': np.mean(f1s),\n",
    "    }\n",
    "\n",
    "    \"\"\"if vis_hist_certainties:\n",
    "        hist_certainties(all_certainties)\"\"\"\n",
    "\n",
    "    return equity, profit_factor, metrics, feature_importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09e683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_certainties(all_certainties):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    axs[0].hist(all_certainties, bins=50, color='blue', alpha=0.7)\n",
    "    axs[0].set_title(\"Distribución de Certeza (max prob)\")\n",
    "    axs[0].set_xlabel(\"Certeza\")\n",
    "    axs[0].set_ylabel(\"Frecuencia\")\n",
    "    axs[0].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3800a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_drawdown(equity):\n",
    "    peak = equity[0]\n",
    "    max_dd = 0\n",
    "    for x in equity:\n",
    "        if x > peak:\n",
    "            peak = x\n",
    "        dd = peak - x\n",
    "        if dd > max_dd:\n",
    "            max_dd = dd\n",
    "    return max_dd if max_dd > 0 else 1e-9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a674136d",
   "metadata": {},
   "source": [
    "# Uncertainty functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cb0d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_impacto_de_thresholds(df_prep, \n",
    "                                features,\n",
    "                                param_rf_default=None,\n",
    "                                threshold_range=np.arange(0.50, 0.705, 0.02),\n",
    "                                n_splits=5):\n",
    "    \n",
    "    if param_rf_default is None:\n",
    "        param_rf_default = {\n",
    "            \"n_estimators\": 100,\n",
    "            \"max_depth\": 5\n",
    "        }\n",
    "\n",
    "    profit_factors = []\n",
    "    profits = []\n",
    "    n_trades = []\n",
    "    thresholds = []\n",
    "    equities = []\n",
    "\n",
    "    for thresh in threshold_range:\n",
    "        equity, pf, metrics, _ = evaluar_modelo_cv(\n",
    "            df_model_base=df_prep,\n",
    "            features=features,\n",
    "            param_rf=param_rf_default,\n",
    "            use_uncertainty=True,\n",
    "            threshold=thresh,\n",
    "            threshold_entropy=None,\n",
    "            future=future,\n",
    "            n_splits=n_splits,\n",
    "            vis_plot=False\n",
    "        )\n",
    "\n",
    "        thresholds.append(thresh)\n",
    "        profit_factors.append(pf)\n",
    "        profits.append(equity[-1] - equity[0])\n",
    "        n_trades.append(len(equity) - 1)\n",
    "        equities.append(equity)\n",
    "        \n",
    "    plot_uncertainty_metrics(thresholds,\n",
    "                                profit_factors,\n",
    "                                profits,\n",
    "                                n_trades,\n",
    "                                )\n",
    "\n",
    "    plot_subplots_equity(equities, \n",
    "                            thresholds,\n",
    "                            profit_factors)\n",
    "    # Gráficos de métricas\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add03d9",
   "metadata": {},
   "source": [
    "# Visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a832b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_slope(equity, exp=None):\n",
    "    \n",
    "    y = equity\n",
    "    x = np.arange(len(y), dtype=float)\n",
    "    slope = float(np.polyfit(x, y, 1)[0])\n",
    "    #ratio_above = (y > 0).mean()\n",
    "    #capital_final = float(y.iloc[-1])\n",
    "    \n",
    "    return slope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d309392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conditional_equity(df_equity, exp=None):\n",
    "    \n",
    "    y = df_equity[\"capital\"]\n",
    "    x = np.arange(y.size, dtype=float)\n",
    "    slope = float(np.polyfit(x, y, 1)[0])\n",
    "    ratio_above = (y > 0).mean()\n",
    "    capital_final = float(y.iloc[-1])\n",
    "    \n",
    "    valid_patterns = []\n",
    "    if slope > 0 and ratio_above > 0.5 and capital_final > 2*abs(min(y)) :\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.plot(df_equity[\"entry_time\"], y, label=\"Equity\")\n",
    "        plt.xlabel(\"Fecha\")\n",
    "        plt.ylabel(\"Capital\")\n",
    "        titulo = f\"Curva de Equity\"\n",
    "        if exp:\n",
    "            titulo += f\" para la expansión {exp}\"\n",
    "        plt.title(titulo)\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(features, importances, metric):\n",
    "\n",
    "    indices = np.argsort(importances)\n",
    "    plt.figure(figsize=(8, len(features) * 0.3 + 1))\n",
    "    plt.barh(range(len(features)), importances[indices], align='center')\n",
    "    plt.yticks(range(len(features)), [features[i] for i in indices])\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.title(f\"Feature importances: {metric}\")\n",
    "    plt.grid(True, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_feature_importances(features, importances):\n",
    "    importances_all = {\n",
    "        'profit': importances[0],\n",
    "        'profit factor': importances[1],\n",
    "        'profit drawdown': importances[2]\n",
    "    }\n",
    "\n",
    "    indices = np.argsort(importances[0])  # podés cambiar por otra métrica si querés otro orden\n",
    "    features_sorted = [features[i] for i in indices]\n",
    "\n",
    "    bar_width = 0.25\n",
    "    y = np.arange(len(features))\n",
    "\n",
    "    plt.figure(figsize=(10, len(features) * 0.3 + 2))\n",
    "\n",
    "    for i, (label, importances) in enumerate(importances_all.items()):\n",
    "        imp = np.array(importances)[indices]\n",
    "        plt.barh(y + i * bar_width, imp, bar_width, label=label)\n",
    "\n",
    "    plt.yticks(y + bar_width, features_sorted)\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.title(\"Comparación de Importancias por Métrica\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def equity_plot(equity_profit, equity_pf, equity_dd):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(equity_profit, label='profit')\n",
    "    plt.plot(equity_pf, label='profit factor')\n",
    "    plt.plot(equity_dd, label='profit drawdown')\n",
    "    plt.title(\"Equity Curves Comparadas\")\n",
    "    plt.xlabel(\"Trades\")\n",
    "    plt.ylabel(\"Capital\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def equity_single_plot(equity, metric):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(equity, label='Equity')\n",
    "    plt.xlabel('Trade Number')\n",
    "    plt.ylabel('Equity')\n",
    "    plt.title(f\"Equity plot: {metric}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755fb860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_equities_por_threshold(df_prep, features,\n",
    "                                    param_rf_default=None,\n",
    "                                    future=None,\n",
    "                                    threshold_range=np.arange(0.50, 0.605, 0.01),\n",
    "                                    n_splits=5):\n",
    "\n",
    "    if param_rf_default is None:\n",
    "        param_rf_default = {\n",
    "            \"n_estimators\": 100,\n",
    "            \"max_depth\": 5\n",
    "        }\n",
    "\n",
    "    equities = []\n",
    "    thresholds = []\n",
    "\n",
    "    for thresh in threshold_range:\n",
    "        equity, _, _, _ = evaluar_modelo_cv(\n",
    "            df_model_base=df_prep,\n",
    "            features=features,\n",
    "            param_rf=param_rf_default,\n",
    "            use_uncertainty=True,\n",
    "            threshold=thresh,\n",
    "            threshold_entropy=None,\n",
    "            future=future,\n",
    "            n_splits=n_splits,\n",
    "            vis_plot=False\n",
    "        )\n",
    "        equities.append(equity)\n",
    "        thresholds.append(thresh)\n",
    "\n",
    "    # Plot\n",
    "    n = len(thresholds)\n",
    "    fig, axs = plt.subplots(n, 1, figsize=(10, 2.5 * n), sharex=False)\n",
    "\n",
    "    for i, (eq, t) in enumerate(zip(equities, thresholds)):\n",
    "        axs[i].plot(eq)\n",
    "        axs[i].set_title(f\"Equity - Threshold={t:.2f}\")\n",
    "        axs[i].set_ylabel(\"Equity\")\n",
    "        axs[i].grid(True)\n",
    "\n",
    "    axs[-1].set_xlabel(\"Trade #\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788ad6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def plot_uncertainty_metrics(thresholds,\n",
    "                                profit_factors,\n",
    "                                profits,\n",
    "                                n_trades,\n",
    "                                ):\n",
    "        fig, axs = plt.subplots(3, 1, figsize=(10, 12), sharex=True)\n",
    "\n",
    "        axs[0].plot(thresholds, profit_factors, marker='o')\n",
    "        axs[0].set_ylabel(\"Profit Factor\")\n",
    "        axs[0].set_title(\"Profit Factor vs Threshold\")\n",
    "        axs[0].grid(True)\n",
    "\n",
    "        axs[1].plot(thresholds, profits, marker='o', color='green')\n",
    "        axs[1].set_ylabel(\"Profit Net\")\n",
    "        axs[1].set_title(\"Profit Neto vs Threshold\")\n",
    "        axs[1].grid(True)\n",
    "\n",
    "        axs[2].plot(thresholds, n_trades, marker='o', color='orange')\n",
    "        axs[2].set_ylabel(\"Cantidad de Trades\")\n",
    "        axs[2].set_xlabel(\"Threshold de Certeza\")\n",
    "        axs[2].set_title(\"Cantidad de Trades vs Threshold\")\n",
    "        axs[2].grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Gráficos de equity\n",
    "    def plot_subplots_equity(equities, \n",
    "                            thresholds,\n",
    "                            profit_factors):\n",
    "        fig, axes = plt.subplots(len(equities), 1, figsize=(12, 3 * len(equities)), sharex=False)\n",
    "        if len(equities) == 1:\n",
    "            axes = [axes]\n",
    "        for i, (eq, th, pf) in enumerate(zip(equities, thresholds, profit_factors)):\n",
    "            axes[i].plot(eq)\n",
    "            axes[i].set_title(f\"Equity Curve - Threshold = {th:.2f} | PF = {pf:.2f}\")\n",
    "            axes[i].set_ylabel(\"Equity\")\n",
    "            axes[i].grid(True)\n",
    "        axes[-1].set_xlabel(\"Trade #\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f384fd",
   "metadata": {},
   "source": [
    "# Legacy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2dfd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def correr_todo():\n",
    "    best_overall_score = -np.inf\n",
    "    best_overall_params = None\n",
    "    best_overall_equity = None\n",
    "    best_overall_future = None\n",
    "    best_overall_past = None\n",
    "\n",
    "    # Diccionario para guardar la mejor equity de cada past\n",
    "    best_equity_per_past = {}\n",
    "    best_score_per_past = {}\n",
    "    best_future_per_past = {}\n",
    "\n",
    "    for future in future_windows:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        best_score_future = -np.inf\n",
    "        best_equities_future = []\n",
    "        labels_future = []\n",
    "        print(f\"--- Future: {future} ---\")\n",
    "        \n",
    "        for past in past_windows:\n",
    "            print(f\"Evaluando past={past}\")\n",
    "            df_prep, features = parse_binance_files(folder_path, past, future, use_time_filter)\n",
    "            \n",
    "            is_last = (past == past_windows[-1]) and (future == future_windows[-1])\n",
    "\n",
    "        if is_last:\n",
    "            equity, params, score, metrics, feat_imp = grid_search_sobre_modelo(\n",
    "                grid_params,\n",
    "                df_prep,\n",
    "                features,\n",
    "                use_uncertainty,\n",
    "                future=future,\n",
    "                vis=True,\n",
    "                vis_plot=True,\n",
    "                optimize_by=scoring\n",
    "            )\n",
    "        else:\n",
    "            equity, params, score, metrics, feat_imp = grid_search_sobre_modelo_parallel(\n",
    "                grid_params,\n",
    "                df_prep,\n",
    "                features,\n",
    "                use_uncertainty,\n",
    "                future=future,\n",
    "                vis=False,\n",
    "                vis_plot=False,\n",
    "                optimize_by=scoring\n",
    "            )\n",
    "\n",
    "            \n",
    "            best_equities_future.append(equity)\n",
    "            labels_future.append(f\"past={past}, score={score:.2f}\")\n",
    "            \n",
    "            if score > best_score_future:\n",
    "                best_score_future = score\n",
    "                best_equity_future = equity\n",
    "                best_params_future = params\n",
    "                best_past_future = past\n",
    "                best_feature_imp = feat_imp\n",
    "            \n",
    "            if (past not in best_score_per_past) or (score > best_score_per_past[past]):\n",
    "                best_score_per_past[past] = score\n",
    "                best_equity_per_past[past] = equity\n",
    "                best_future_per_past[past] = future\n",
    "            \n",
    "            if score > best_overall_score:\n",
    "                best_overall_score = score\n",
    "                best_overall_params = params\n",
    "                best_overall_equity = equity\n",
    "                best_overall_future = future\n",
    "                best_overall_past = past\n",
    "                best_overall_feature_imp = feat_imp\n",
    "                features_of_the_overall_best = features\n",
    "\n",
    "        \"\"\"for eq, label in zip(best_equities_future, labels_future):\n",
    "            plt.plot(eq, label=label)\n",
    "        plt.title(f\"Equity curves - Future={future}\")\n",
    "        plt.xlabel(\"Trade Number\")\n",
    "        plt.ylabel(\"Equity\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\"\"\"\n",
    "\n",
    "    print()\n",
    "    print(\"Mejores equity curves: \")\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for past, equity in best_equity_per_past.items():\n",
    "        future = best_future_per_past[past]\n",
    "        plt.plot(equity, label=f\"Best past={past}, future={future}\")\n",
    "    plt.title(\"Mejores Equity Curves por cada Past (superpuestas)\")\n",
    "    plt.xlabel(\"Trade Number\")\n",
    "    plt.ylabel(\"Equity\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    best_results = {\n",
    "        'score': best_overall_score,\n",
    "        'params': best_overall_params,\n",
    "        'equity': best_overall_equity,\n",
    "        'future': best_overall_future,\n",
    "        'past': best_overall_past,\n",
    "        'feature_importance': best_overall_feature_imp,\n",
    "        'features': features_of_the_overall_best\n",
    "    }\n",
    "\n",
    "    filename = f\"best_results_past{past}_future{future}_timefilter{use_time_filter}_uncertainty{use_uncertainty}_tresh{threshold}_scoring{scoring}.pkl\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(best_results, f)\n",
    "\n",
    "    print(f\"Mejor combinación general: future={best_overall_future}, past={best_overall_past}\")\n",
    "    print(f\"Mejores parámetros: {best_overall_params}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
